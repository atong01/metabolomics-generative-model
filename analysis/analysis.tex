\documentclass[11pt]{article}

% -- Semantics stuff
%     I defined a couple of special commands (see examples in the text below) to make
%     writing inference rules and judgements easier.
\newcommand{\br}[1]{\langle #1 \rangle}
\def\Yields{\Downarrow}

% -- Page size
\textheight     9.0truein
\textwidth      6.5truein
\topmargin     -0.5truein
\oddsidemargin  +0.0truein
\evensidemargin +0.0truein
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{fullpage}
\usepackage{enumerate}
\usepackage[mathscr]{euscript}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\renewcommand{\theenumi}{\roman{enumi}}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}

\newenvironment{proof}[1][Proof]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{definition}[1][Definition]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{example}[1][Example]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}
\newenvironment{remark}[1][Remark]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}

\newcommand{\qed}{\nobreak \ifvmode \relax \else
      \ifdim\lastskip<1.5em \hskip-\lastskip
      \hskip1.5em plus0em minus0.5em \fi \nobreak
      \vrule height0.75em width0.5em depth0.25em\fi}


% -- Document title (appears at top)
\title{Metabolomics Generative Model Analysis}
\author{Alex Tong}
\begin{document}
\maketitle

Parameters:
\begin{itemize}
\item[$\lambda_p$:] Probability that a pathway is active
\item[$\mu_0$:] Probability that a feature is present given inactive pathway
\item[$\mu_1$:] Probability that a feature is present given active pathway
\end{itemize}

Variables:
\begin{itemize}
\item [$a_p$:] IRV indicating pathway $p$ activity
\item [$b_{p,f}$:] IRV indicating feature f is associated with pathway p
\item[$o_{p,f}$:] IRV indicating whether feature $f$ associated with pathway $p$ is present in the sample due to pathway $p$
\item[$m_f$:] IRV indicating whether feature $f$ is present in the sample
\item[$v_f$:] IRV (virtual evidence on feature f
\end{itemize}

Generative Model Prior:
\begin{itemize}
\item [$a_p$:] $Bernoulli(\lambda_p)$ for $p = 1 ... P$
\item [$o_{p,f} | a_p, \mu$:] $Bernoulli(\mu_{a_p})$ for $f$ in Features($p$)
\item [$m_f$]  $= (1 -  \prod_p (1 - o_{p,f}))$ Equivalent to logical OR
\item [$v_f$] $= Bernoulli$(Measured P($f$))
\end{itemize}

Observation:
\begin{itemize}
\item [$v_f$] $ = 1$
\end{itemize}

Posterior:

\begin{align}
p(o | \lambda, \mu_0, \mu_1, b_{p,f}, a_p) &= \prod_p \prod_{f} (\mu_{a_p}^{o_{p,f}} (1-\mu_{a_p})^{(1-o_{p,f})})^{b_{p,f}} \\
p(m | o, b) &= \prod_f m_f = \prod_f (1 - \prod_p (1 - o_{p,f})^{b_{p,f}}) \\
p(\lambda, \mu_0, \mu_1, a, o, m) &= p(a | \lambda )p(\lambda) p(\mu_0) p(\mu_1) p( o | \lambda, \mu_0, \mu_1, b_{p,f}) p(m | o) \\
p(\lambda, \mu_0, \mu_1, a, o, m | v = \mathbf{1}) &= \frac{p(v | \lambda, \mu_0, \mu_1, a, o, y) * p(\lambda, \mu_0, \mu_1, a, o, m)}{p(v = \mathbf{1})}  \\
&\propto p(v | m) * p(\lambda, \mu_0, \mu_1, a, o, m) 
\end{align}
%p(\alpha | v = \mathbf{1}) &= 

Description:
Equation 1 shows the likelihood of a given set of $o$ variables. For example, if I wanted to calculate the probability of all $o_{p,f}$ variables being zero, I would need all given hyperparameters, $\lambda, \mu_0, \mu_1$, and the values of $a_p$. The likelihood as stated is a function of $p$ variables, $a_{1...p}$. Note that with this likelihood function, it is simple to calculate the likelihood $P(o | \lambda, \mu_0, \mu_1, a)$, In fact, for a given $o_{p,f}$, we can calculate $p(o_{p,f} | a_p, b_{p,f}) = \mu_{a_p}^{o_{p,f}} (1-\mu_{a_p})^{(1-o_{p,f})}$ or 
$$p(o_{p,f} = 1 | a_p, b_{p,f}) = \mu_{a_p}$$
$$p(o_{p,f} = 0 | a_p, b_{p,f}) = 1-\mu_{a_p}$$
Equation 2 shows the likelihood of a set of metabolite observations given $o$. for example, the probability of getting $m_1 = 1, m_2 = 0, m_3 = 1$ given all of $o$, is a constant.\\\\
Equation 3 shows the likelihood over all hidden variables. This is derived from looking at our bayesian network, as each variable is independent.\\\\
Equation 4 shows the model likelihood given our observation of our virtual nodes. This is derived from bayes rule. \\\\

$$p(v_f | m_f) = P(metfrag)  * P(\pi)$$

Reasonable Values:
\begin{itemize}
\item $\pi$ should be nominally quite low, and may be lower for some metabolites than others???
\end{itemize}

\end{document}
